(window.webpackJsonp=window.webpackJsonp||[]).push([[93],{480:function(e,t,r){"use strict";r.r(t);var a=r(54),s=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"hyperloglog"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#hyperloglog"}},[e._v("#")]),e._v(" HyperLogLog")]),e._v(" "),r("p"),r("div",{staticClass:"table-of-contents"},[r("ul",[r("li",[r("a",{attrs:{href:"#overview"}},[e._v("Overview")])]),r("li",[r("a",{attrs:{href:"#theory"}},[e._v("Theory")])]),r("li",[r("a",{attrs:{href:"#enhancements"}},[e._v("Enhancements")]),r("ul",[r("li",[r("a",{attrs:{href:"#hyperloglog"}},[e._v("HyperLogLog++")])])])]),r("li",[r("a",{attrs:{href:"#tools"}},[e._v("Tools")]),r("ul",[r("li",[r("a",{attrs:{href:"#redis"}},[e._v("Redis")])]),r("li",[r("a",{attrs:{href:"#datasketch"}},[e._v("Datasketch")])]),r("li",[r("a",{attrs:{href:"#logswan"}},[e._v("Logswan")])])])]),r("li",[r("a",{attrs:{href:"#strategies"}},[e._v("Strategies")]),r("ul",[r("li",[r("a",{attrs:{href:"#short-term-bucket-long-term-merge"}},[e._v("Short-term Bucket & Long-term Merge")])])])])])]),r("p"),e._v(" "),r("h2",{attrs:{id:"overview"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),r("p",[e._v("HyperLogLog is an algorithm that can solve "),r("a",{attrs:{href:"count-distinct"}},[e._v("Count Distinct")]),e._v(" problem. A Count Distinct problem is something like getting number 5 for a data set like [1, 3, 2, 1, 5, 2, 4], for it has [1, 2, 3, 4, 5] 5 elements.")]),e._v(" "),r("p",[e._v("HyperLogLog can provide estimated count on a very large data stream.")]),e._v(" "),r("ul",[r("li",[e._v("Advantage\n"),r("ul",[r("li",[e._v("Fast (O(1)).")]),e._v(" "),r("li",[e._v("Memory efficient.")]),e._v(" "),r("li",[e._v("Can be distributed and paralleled.")])])]),e._v(" "),r("li",[e._v("Disadvantage\n"),r("ul",[r("li",[e._v("Only provides estimated count.")])])])]),e._v(" "),r("h2",{attrs:{id:"theory"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#theory"}},[e._v("#")]),e._v(" Theory")]),e._v(" "),r("ul",[r("li",[e._v("Hash each item.")]),e._v(" "),r("li",[e._v("Place each item into 32 buckets based on first 5-bits of the hash.")]),e._v(" "),r("li",[e._v("Update value for each item in 32 buckets based on last 27-bits of the hash.")]),e._v(" "),r("li",[e._v("Apply to some fancy mathematical formulas to get the number based on the 32 buckets data.")])]),e._v(" "),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://blog.notdot.net/2012/09/Dam-Cool-Algorithms-Cardinality-Estimation",target:"_blank",rel:"noopener noreferrer"}},[e._v("Damn Cool Algorithms: Cardinality Estimation"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.moderndescartes.com/essays/hyperloglog/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Using Linear Counting, LogLog, and HyperLogLog to Estimate Cardinality"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://djhworld.github.io/hyperloglog/",target:"_blank",rel:"noopener noreferrer"}},[e._v("HyperLogLog  Playground"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"enhancements"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#enhancements"}},[e._v("#")]),e._v(" Enhancements")]),e._v(" "),r("h3",{attrs:{id:"hyperloglog-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#hyperloglog-2"}},[e._v("#")]),e._v(" HyperLogLog++")]),e._v(" "),r("p",[e._v("HyperLogLogPlusPlus is an enhancement of HyperLogLog.")]),e._v(" "),r("ul",[r("li",[e._v("Uses 64-bit integers rather than 32-bit")]),e._v(" "),r("li",[e._v("Sparse data structure rather than one huge array")]),e._v(" "),r("li",[e._v("Better bias correction algorithm at lower cardinalities.")])]),e._v(" "),r("h2",{attrs:{id:"tools"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#tools"}},[e._v("#")]),e._v(" Tools")]),e._v(" "),r("h3",{attrs:{id:"redis"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#redis"}},[e._v("#")]),e._v(" Redis")]),e._v(" "),r("p",[e._v("Commands "),r("code",[e._v("PFADD")]),e._v(", "),r("code",[e._v("PFCOUNT")]),e._v(", and "),r("code",[e._v("PFMERGE")]),e._v(" are the main interfaces for manipulating HyperLogLog data structure in Redis.")]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v('redis> PFADD hll a b c d e f g\n(integer) 1\nredis> PFCOUNT hll\n(integer) 7\n\nredis> PFADD hll1 foo bar zap a\n(integer) 1\nredis> PFADD hll2 a b c foo\n(integer) 1\nredis> PFMERGE hll3 hll1 hll2\n"OK"\nredis> PFCOUNT hll3\n(integer) 6\n')])])]),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://antirez.com/news/75",target:"_blank",rel:"noopener noreferrer"}},[e._v("Redis new data structure: the HyperLogLog"),r("OutboundLink")],1),e._v(": If you're developing a web service, Redis might be a good choice.")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://robots.thoughtbot.com/hyperloglogs-in-redis",target:"_blank",rel:"noopener noreferrer"}},[e._v("HyperLogLogs in Redis"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://redis.io/commands/pfadd",target:"_blank",rel:"noopener noreferrer"}},[e._v("PFADD"),r("OutboundLink")],1),e._v(": Add all the element arguments to the HyperLogLog data structure referenced as "),r("code",[e._v("key")]),e._v(".")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://redis.io/commands/pfcount",target:"_blank",rel:"noopener noreferrer"}},[e._v("PFCOUNT"),r("OutboundLink")],1),e._v(": Get the approximated cardinality computed by the HyperLogLog data structure")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://redis.io/commands/pfmerge",target:"_blank",rel:"noopener noreferrer"}},[e._v("PFMERGE"),r("OutboundLink")],1),e._v(": Merge multiple HyperLogLog values into one.")])]),e._v(" "),r("h3",{attrs:{id:"datasketch"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#datasketch"}},[e._v("#")]),e._v(" Datasketch")]),e._v(" "),r("p",[e._v("Source code of the script "),r("code",[e._v("test.py")]),e._v(":")]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("from datasketch import HyperLogLog\n\ndata = [1, 2, 3, 5, 2, 4, 1, 6, 7]\n\nhll = HyperLogLog()\nfor element in data:\n    hll.update(str(element).encode('utf8'))\n\nprint(f'estimate: {hll.count()}')\nprint(f'real: {len(set(data))}')\n")])])]),r("p",[e._v("Run the script:")]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("$ mkdir testdatasketch\n$ python3 -mvenv venv\n$ source venv/bin/activate\n(venv) $ pip install datasketch\n(venv) $ python test.py\nestimate: 7.097484291802821\nreal: 7\n")])])]),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://ekzhu.github.io/datasketch/hyperloglog.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("datasketch - big data looks small"),r("OutboundLink")],1),e._v(": If you're trying to write a simple Python script to solve problem, datasketch might be a good choice.")])]),e._v(" "),r("h3",{attrs:{id:"logswan"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#logswan"}},[e._v("#")]),e._v(" Logswan")]),e._v(" "),r("p",[e._v("Logswan can find unique IP addresses in very large log files but only consumes 4MB memory.")]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("$ logswan access.log\n")])])]),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://www.logswan.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("logswan - Fast Web log analyzer using probabilistic data structures"),r("OutboundLink")],1),e._v(": Good choice for unique visitors counting on common logging file.")])]),e._v(" "),r("h2",{attrs:{id:"strategies"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#strategies"}},[e._v("#")]),e._v(" Strategies")]),e._v(" "),r("h3",{attrs:{id:"short-term-bucket-long-term-merge"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#short-term-bucket-long-term-merge"}},[e._v("#")]),e._v(" Short-term Bucket & Long-term Merge")]),e._v(" "),r("ul",[r("li",[e._v("Keep HyperLogLog data for every 10 minutes for the past 24 hours.")]),e._v(" "),r("li",[e._v("Merge HyperLogLog data into hourly HLL after 24 hours.")]),e._v(" "),r("li",[e._v("Merge HyperLogLog data into daily HLL after 60 days.")]),e._v(" "),r("li",[e._v("...")])]),e._v(" "),r("p",[e._v("Example redis usage: "),r("code",[e._v("PFADD users:<date>:<hour>:<MM> <UID>")]),e._v(", MM=[00, 10, 20, 30, 40, 50]")]),e._v(" "),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://gist.github.com/DavidJFelix/113fad6a0a7affdd880d",target:"_blank",rel:"noopener noreferrer"}},[e._v("A lab for HyperLogLogs using Redis & Python"),r("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=s.exports}}]);