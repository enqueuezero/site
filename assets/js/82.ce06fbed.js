(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{471:function(e,t,a){"use strict";a.r(t);var s=a(54),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"actor-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#actor-model"}},[e._v("#")]),e._v(" Actor Model")]),e._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#context"}},[e._v("Context")])]),a("li",[a("a",{attrs:{href:"#introduction"}},[e._v("Introduction")])]),a("li",[a("a",{attrs:{href:"#solutions"}},[e._v("Solutions")]),a("ul",[a("li",[a("a",{attrs:{href:"#erlang-elixir"}},[e._v("Erlang, Elixir")])]),a("li",[a("a",{attrs:{href:"#akka"}},[e._v("Akka")])]),a("li",[a("a",{attrs:{href:"#skynet"}},[e._v("Skynet")])])])]),a("li",[a("a",{attrs:{href:"#patterns"}},[e._v("Patterns")]),a("ul",[a("li",[a("a",{attrs:{href:"#small-memory-footprint"}},[e._v("Small Memory Footprint")])]),a("li",[a("a",{attrs:{href:"#mailbox-and-message-passing"}},[e._v("Mailbox and Message Passing")])]),a("li",[a("a",{attrs:{href:"#schedule-system"}},[e._v("Schedule System")])]),a("li",[a("a",{attrs:{href:"#ready-queue-waiting-queue"}},[e._v("Ready Queue & Waiting Queue")])]),a("li",[a("a",{attrs:{href:"#let-it-crash"}},[e._v("Let it crash")])]),a("li",[a("a",{attrs:{href:"#distribution"}},[e._v("Distribution")])])])]),a("li",[a("a",{attrs:{href:"#conclusions"}},[e._v("Conclusions")])])])]),a("p"),e._v(" "),a("h2",{attrs:{id:"context"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context"}},[e._v("#")]),e._v(" Context")]),e._v(" "),a("p",[e._v("Concurrency means we could run multiple tasks upon single CPU core.")]),e._v(" "),a("p",[e._v("Multiprocess and multithreading are the two most popular ways of doing concurrency. It leverages Operating System's process and thread (lightweight process). The problem is that data sharing is a problem, especially in multithreading. We need to apply locks to the shared data.")]),e._v(" "),a("p",[e._v("The actor model is another concurrency technology.")]),e._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("The actor is an isolated concurrent unit scheduled by the programming language.")]),e._v(" "),a("p",[e._v("It's far more lightweight than processes or threads, so you can have hundreds of thousands of actors running simultaneously.")]),e._v(" "),a("p",[e._v("Actors are isolated from each other, meaning no actor can access other actors' data in memory. Instead, if needed, they communicate with each other via message passing.")]),e._v(" "),a("h2",{attrs:{id:"solutions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#solutions"}},[e._v("#")]),e._v(" Solutions")]),e._v(" "),a("h3",{attrs:{id:"erlang-elixir"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#erlang-elixir"}},[e._v("#")]),e._v(" Erlang, Elixir")]),e._v(" "),a("p",[e._v("In the telecom industry, we find heavy use of Erlang. The actor model makes the system more reliable. Below hello world example shows the two fundamental operators: send and receive.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('pid = spawn fn ->\n  receive do\n    {:hello, msg} -> IO.puts(msg)\n  end\nend\n\nsend pid, {:hello, "world"}\n')])])]),a("h3",{attrs:{id:"akka"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#akka"}},[e._v("#")]),e._v(" Akka")]),e._v(" "),a("p",[e._v("Akka is de facto actor model implementation in Java and Scala.")]),e._v(" "),a("p",[e._v("It has a similar operator like Erlang and Elixir. Check "),a("a",{attrs:{href:"https://developer.lightbend.com/guides/akka-quickstart-scala/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Akka Quickstart with Scala"),a("OutboundLink")],1),e._v(" for Hello World example. It's a little bit complicated than elixir example above.")]),e._v(" "),a("h3",{attrs:{id:"skynet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#skynet"}},[e._v("#")]),e._v(" Skynet")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/cloudwu/skynet",target:"_blank",rel:"noopener noreferrer"}},[e._v("Skynet"),a("OutboundLink")],1),e._v(" is a lightweight C-implemented actor system.")]),e._v(" "),a("h2",{attrs:{id:"patterns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#patterns"}},[e._v("#")]),e._v(" Patterns")]),e._v(" "),a("h3",{attrs:{id:"small-memory-footprint"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#small-memory-footprint"}},[e._v("#")]),e._v(" Small Memory Footprint")]),e._v(" "),a("p",[e._v("OS process or thread needs to have minimum a few megabytes memory in OS.")]),e._v(" "),a("p",[e._v("Actors are tiny in contrast. It varies from implementations, but it generally needs only a few hundreds of bytes. That's why it can have hundreds of thousands of actors when consuming 1GB memory.")]),e._v(" "),a("p",[e._v("An actor has very few data in its data structure:")]),e._v(" "),a("ul",[a("li",[e._v("State")]),e._v(" "),a("li",[e._v("Behaviour")]),e._v(" "),a("li",[e._v("Mailbox")])]),e._v(" "),a("h3",{attrs:{id:"mailbox-and-message-passing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mailbox-and-message-passing"}},[e._v("#")]),e._v(" Mailbox and Message Passing")]),e._v(" "),a("p",[e._v("Every actor has a mailbox, just like a mailbox in front of every house. It's a FIFO message queue that stores message sending from other actors.")]),e._v(" "),a("p",[e._v("The sequence of messages delivered to a mailbox determines the code be synchronized. The actor reacts by the following Message and suspends when no new Message.")]),e._v(" "),a("p",[e._v("Generally, the mailbox is a lock-free queue. Check "),a("RouterLink",{attrs:{to:"/concepts/lock-free-queues.html"}},[e._v("Lock-Free Queues")]),e._v(" If you want to know more.")],1),e._v(" "),a("h3",{attrs:{id:"schedule-system"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#schedule-system"}},[e._v("#")]),e._v(" Schedule System")]),e._v(" "),a("p",[e._v("The schedule system schedules when to run an actor. As a developer, you wouldn't necessarily need to use schedule system generally.")]),e._v(" "),a("p",[e._v("The scheduling system has two major implementations:")]),e._v(" "),a("ul",[a("li",[e._v("Use underlying OS threads.")]),e._v(" "),a("li",[e._v("VM implement its micro-threads.")])]),e._v(" "),a("h3",{attrs:{id:"ready-queue-waiting-queue"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ready-queue-waiting-queue"}},[e._v("#")]),e._v(" Ready Queue & Waiting Queue")]),e._v(" "),a("p",[e._v("Schedule system maintains two queues:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("ready_queue")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("waiting_queue")]),e._v(".")])]),e._v(" "),a("p",[e._v("Below is a possible set of rules:")]),e._v(" "),a("ul",[a("li",[e._v("Scheduler picks the HEAD of "),a("code",[e._v("ready_queue")]),e._v(" to run inside VM for a given time slice.")]),e._v(" "),a("li",[e._v("Scheduler moves the head of "),a("code",[e._v("ready_queue")]),e._v(" to the END of "),a("code",[e._v("ready_queue")]),e._v(" if the Proc can't finish in a given time slice.")]),e._v(" "),a("li",[e._v("Scheduler moves the HEAD of "),a("code",[e._v("ready_queue")]),e._v(" to the END of "),a("code",[e._v("waiting_queue")]),e._v(" if "),a("code",[e._v("recv")]),e._v(" blocks the Proc.")]),e._v(" "),a("li",[e._v("Scheduler moves a Proc from "),a("code",[e._v("waiting_queue")]),e._v(" to "),a("code",[e._v("ready_queue")]),e._v(" if it receives a message or waiting for the timeout.")])]),e._v(" "),a("p",[e._v("Note that at a specific moment, there is only one instruction of a Proc is running in single CPU core. On a multiple CPU core machine, VM can create various schedulers.")]),e._v(" "),a("h3",{attrs:{id:"let-it-crash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#let-it-crash"}},[e._v("#")]),e._v(" Let it crash")]),e._v(" "),a("p",[e._v("An actor might crash, just like process might crash. "),a("code",[e._v("Let it crash")]),e._v(" is a philosophy of isolating bad actors from crashing but leaving all other actors running as usual. Usually, a supervisor watches all actors. If an actor crashed, then it will try to do something based on your configured strategy, for example, restarting the actor.")]),e._v(" "),a("h3",{attrs:{id:"distribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#distribution"}},[e._v("#")]),e._v(" Distribution")]),e._v(" "),a("p",[e._v("The actor doesn't care where the message comes. It can be from another actor in the same process or from another process in another machine.")]),e._v(" "),a("p",[e._v("This feature combining let-it-crash philosophy makes actor a perfect solution to build a robust distributed system.")]),e._v(" "),a("h2",{attrs:{id:"conclusions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#conclusions"}},[e._v("#")]),e._v(" Conclusions")]),e._v(" "),a("p",[e._v("The actor model is yet another concurrency solution. The benefit is lock-free. The downside is only a few tools or framework support it. Either way, if you're stuck at lock when doing concurrent programming, try actor model.")])])}),[],!1,null,null,null);t.default=r.exports}}]);